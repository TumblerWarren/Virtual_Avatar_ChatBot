#Enter your input choice || Speech or Text
INPUT_CHOICE=Speech

#Enter your desired chatbot || oogabooga or betacharacter or local_llm or collab_llm
CHATBOT_SERVICE=collab_llm

#Enter the Ngrok URL which you have got from Google Collab.
ngrok_url=https://90d8-34-32-215-157.ngrok-free.app

#If you have selected chatbot as oogabooga please enter the name of the charceter card you uploaded.
CHARACTER_CARD = Ayaka

#Only if you are using oogabooga, enter your name that you entered while creating Character card. Typically USER,YOU or if have entered your name.
your_name = Warren

#Enter your PyChai API, How to link :- https://pycai.gitbook.io/welcome/api/values
PYCHAI=Enter your charecter.ai API.

#Enter your charecter key, How to link :- https://pycai.gitbook.io/welcome/api/values
CHARECTER_KEY= Charecter Token here

#Enter your Text to Speech Choice | ELEVENLABS or VOICEVOX(Japanese Only) |LOCAL_TTS is out of support now,I will add it after fixing the problem
TTS_CHOICE = VOICEVOX

#If you have selected Voicevox, enter the voice ID, you can find the voice id from docs VOICEVOX_HELP.
VOICE_ID=2

#Do you have GPU/CUDA, if yes then write True else write False
CUDA_STATUS=True

#Enter your Elevenlabs Api key, How to link :- https://docs.elevenlabs.io/api-reference/quick-start/authentication
ELEVENLAB_KEY= YOUR API

#If you have selected Elevenlabs, enter you model of choice. You can see examples from Elevenlabs website.
VOICE_MODEL=Sarah

#Enter your whisper model, see VRAM requirement for further details at whisper Github | tiny, base, small
WHISPER_MODEL=base

#Want to speak in english or your native language | TRANSCRIBE, TRANSLATE
WHISPER_CHOICE=TRANSCRIBE
